---
- hosts: localhost
  connection: local
  gather_facts: False

  vars_files:
    - test_vars.yml
    - /mnt/parameters.yml

  tasks:
    - block:

         ## PRE-CHAOS APPLICATION LIVENESS CHECK
        - include_tasks: /utils/k8s/application_liveness_check.yml
          when: liveness_label != ''

        - include: test_prerequisites.yml

        - include_vars:
            file: data_persistence.yml

        - include_vars:
            file: chaosutil.yml

        - name: Record the chaos util path
          set_fact: 
            chaos_util_path: "/chaoslib/{{ chaosutil }}"

        - name: Record the data consistency util path
          set_fact:
            data_consistency_util_path: "{{ consistencyutil }}"
          when: data_persistence != ''

        ## RECORD START-OF-TEST IN LITMUS RESULT CR
        - include_tasks: /utils/fcm/create_testname.yml

        - include_tasks: /utils/fcm/update_e2e_result_resource.yml
          vars:
            status: 'SOT'
            chaostype: "{{ chaosutil.split('.')[0] }}"

        ## DISPLAY APP INFORMATION 
 
        - name: Display the app information passed via the test job
          debug: 
            msg: 
              - "The application info is as follows:"
              - "Namespace           : {{ namespace }}"
              - "Target Namespace    : {{ target_namespace }}"
              - "Label               : {{ label }}"
              - "PVC                 : {{ pvc }}"  
              - "StorageClass        : {{ sc }}"

        ## PRE-CHAOS APPLICATION LIVENESS CHECK

        - name: Verify that the AUT (Application Under Test) is running 
          include_tasks: "/utils/k8s/status_app_pod.yml"
          vars:
            app_ns: "{{namespace}}" 
            app_lkey: "{{ label.split('=')[0] }}"
            app_lvalue: "{{ label.split('=')[1] }}"       
            delay: 5
            retries: 60

        - name: Get application pod name
          shell: >
            kubectl get pods -n {{ namespace }} -l {{ label }} --no-headers
            -o=custom-columns=NAME:".metadata.name"
          args:
            executable: /bin/bash
          register: app_pod_name    

        - name: Derive PV from application PVC 
          shell: >
            kubectl get pvc {{ pvc }}
            -o custom-columns=:spec.volumeName -n {{ namespace }}
            --no-headers
          args:
            executable: /bin/bash
          register: pv

        - block:

            - name: Identify the patch to be invoked
              template:
                src: patch.j2
                dest: patch.yml

            - name: Identify the jiva controller pod name
              shell: >
                kubectl get pods -l openebs.io/controller=jiva-controller
                -n {{ target_namespace }} --no-headers | grep {{ pv.stdout }} 
                | awk '{print $1}' 
              args:
                executable: /bin/bash
              register: controller_pod_before

            - name: Patching jiva controller deployment to allow security privileged
              shell: >
                kubectl patch deployment {{ pv.stdout }}-ctrl -n {{ target_namespace }}
                --patch "$(cat patch.yml)"
              register: patch_status
              failed_when: "'patched' not in patch_status.stdout"
            
            - name: Wait for 10s post fault injection 
              wait_for:
                timeout: 10

            - name: Verify if the jiva controller pod is terminated
              shell: kubectl get pods -n {{ target_namespace }}
              args:
                executable: /bin/bash
              register: pod_status
              until: '"{{ controller_pod_before.stdout }}" not in pod_status.stdout' 
              delay: 5
              retries: 60
              when: "'no change' not in patch_status.stdout"
              
            - name: Identify the new jiva controller pod belonging to the PV
              shell: > 
                kubectl get pods -l openebs.io/controller=jiva-controller
                -n {{ target_namespace }} --no-headers | grep {{ pv.stdout }} 
                | awk '{print $1}'
              args:
                executable: /bin/bash
              register: controller_pod_after

            - name: Check for the jiva controller container status
              shell: >
                kubectl get pods {{ controller_pod_after.stdout }} -n {{ target_namespace }} 
                -o jsonpath='{.status.containerStatuses[?(@.name=="{{ pv.stdout}}-ctrl-con")].state}' | grep running
              args:
                executable: /bin/bash
              register: container_status
              until: "'running' in container_status.stdout"
              delay: 3
              retries: 20
                                      
          when: stg_engine == 'jiva'

        - name: Create some test data
          include: "{{ data_consistency_util_path }}"
          vars:
            status: 'LOAD'
            ns: "{{ namespace }}"
            pod_name: "{{ app_pod_name.stdout }}"
          when: data_persistence != ''

        ## STORAGE FAULT INJECTION 

        - include: "{{ chaos_util_path }}"
          app_ns: "{{ namespace }}"
          target_ns: "{{ target_namespace }}"
          app_pvc: "{{ pvc }}"

        ## POST-CHAOS APPLICATION LIVENESS CHECK

        - name: Wait (soak) for I/O on pools 
          wait_for:
            timeout: "{{ chaos_duration }}"

        - name: Verify AUT liveness post fault-injection
          include_tasks: "/utils/k8s/status_app_pod.yml"
          vars:
            app_ns: "{{namespace}}" 
            app_lkey: "{{ label.split('=')[0] }}"
            app_lvalue: "{{ label.split('=')[1] }}"       
            delay: 5
            retries: 60        

        ## POST-CHAOS APPLICATION LIVENESS CHECK
        - include_tasks: /utils/k8s/application_liveness_check.yml
          when: liveness_label != ''

        - name: Get application pod name
          shell: >
            kubectl get pods -n {{ namespace }} -l {{ label }} --no-headers
            -o=custom-columns=NAME:".metadata.name"
          args:
            executable: /bin/bash
          register: rescheduled_app_pod  

        - name: Verify application data persistence
          include: "{{ data_consistency_util_path }}"
          vars:
            status: 'VERIFY'
            ns: "{{ namespace }}"
            pod_name: "{{ rescheduled_app_pod.stdout }}"                 
          when: data_persistence != ''

        ## Check application-target pod affinity
        - include_tasks: /utils/scm/openebs/target_affinity_check.yml
          vars:
            app_ns: "{{ namespace }}"
            #operator_ns: works by var scope
            app_label: "{{ label }}"
            app_pvc: "{{ pvc }}"
          when: deploy_type == 'deployment' and target_affinity_check == 'enable'

          ## Check statefulset application-target pod affinity
        - include_tasks: /utils/scm/openebs/sts_target_affinity_check.yml
          vars:
            app_ns: "{{ namespace }}"
            app_label: "{{ label }}"
          when: deploy_type == 'statefulset' and target_affinity_check == 'enable'

        - set_fact:
            flag: "Pass"

      rescue: 
        - set_fact: 
            flag: "Fail"

      always: 

        ## RECORD END-OF-TEST IN LITMUS RESULT CR
 
        - include_tasks: /utils/fcm/update_e2e_result_resource.yml
          vars:
            status: 'EOT'
            chaostype: "{{ chaosutil.split('.')[0] }}"
