---
- hosts: localhost
  connection: local
  gather_facts: False

  vars_files:
    - test_vars.yml
    - /mnt/parameters.yml

  tasks:
    - block:

        - include_tasks: /utils/k8s/application_liveness_check.yml
          when: liveness_label != ''    

        ## DERIVE THE APP STORAGE CLASS AND CHAOS UTIL TO USE

        - include: test_prerequisites.yml

        - include_vars:
            file: data_persistence.yml

        - name: Record the data consistency util path
          set_fact:
            data_consistency_util_path: "{{ consistencyutil }}"
          when: data_persistence != ''

        ## RECORD START-OF-TEST IN LITMUS RESULT CR
        
        - include_tasks: /utils/fcm/create_testname.yml

        - include_tasks: /utils/fcm/update_e2e_result_resource.yml
          vars:
            status: 'SOT'
            chaostype: target-network-loss

        ## DISPLAY APP INFORMATION

        - name: Display the app information passed via the test job
          debug:
            msg:
              - "The application info is as follows:"
              - "Namespace    : {{ namespace }}"
              - "Label        : {{ label }}"
              - "PVC          : {{ pvc }}"
              - "StorageClass : {{ sc }}"

        ## PRE-CHAOS APPLICATION LIVENESS CHECK
        - name: Verify that the AUT (Application Under Test) is running
          include_tasks: "/utils/k8s/status_app_pod.yml"
          vars:
            app_ns: "{{namespace}}" 
            app_lkey: "{{ label.split('=')[0] }}"
            app_lvalue: "{{ label.split('=')[1] }}"       
            delay: 5
            retries: 60

        - name: Get application pod name
          shell: >
            kubectl get pods -n {{ namespace }} -l {{ label }} --no-headers
            -o=custom-columns=NAME:".metadata.name"
          args:
            executable: /bin/bash
          register: app_pod_name

        - name: Create some test data
          include: "{{ data_consistency_util_path }}"
          vars:
            status: 'LOAD'
            ns: "{{ namespace }}"
            pod_name: "{{ app_pod_name.stdout }}"
          when: data_persistence != ''

        - name: Derive PV from application PVC 
          shell: >
            kubectl get pvc {{ pvc }}
            -o custom-columns=:spec.volumeName -n {{ namespace }}
            --no-headers
          args:
            executable: /bin/bash
          register: pv

        - name: Pick a cStor target pod belonging to the PV
          shell: >
            kubectl get pods -l openebs.io/target=cstor-target
            -n {{ operator_ns }} --no-headers | grep {{ pv.stdout }}
            | shuf -n1 | awk '{print $1}'
          args:
            executable: /bin/bash
          register: cstor_target_pod
          when: stg_engine == 'cstor'
        
        - block:

            - name: Identify the patch to be invoked
              template:
                src: patch.j2
                dest: patch.yml

            - name: Patching jiva controller deployment to allow security privileged
              shell: >
                kubectl patch deployment {{ pv.stdout }}-ctrl -n {{ operator_ns }}
                --patch "$(cat patch.yml)"
              register: patch_status
              failed_when: "'patched' not in patch_status.stdout"
            
            - name: Wait for 10s post fault injection 
              wait_for:
                timeout: 10

            - name: Identify the jiva controller pod belonging to the PV
              shell: > 
                kubectl get pods -l openebs.io/controller=jiva-controller
                -n {{ operator_ns }} --no-headers | grep {{ pv.stdout }} 
                | awk '{print $1}'
              args:
                executable: /bin/bash
              register: controller_pod

            - name: Check for the jiva controller container status
              shell: >
                kubectl get pods {{ controller_pod.stdout }} -n {{ operator_ns }} 
                -o jsonpath='{.status.containerStatuses[?(@.name=="{{ pv.stdout}}-ctrl-con")].state}' | grep running
              args:
                executable: /bin/bash
              register: container_status
              until: "'running' in container_status.stdout"
              delay: 3
              retries: 20

            - include: /chaoslib/openebs/inject_packet_loss_tc.yml
              vars:
                status: "induce"
                target_pod: "{{ controller_pod.stdout }}"
                operator_namespace: "{{ operator_ns }}"
                containername: "{{ pv.stdout }}-ctrl-con"              
                                      
          when: 
            - stg_engine == 'jiva'
            - stg_prov == 'openebs.io/provisioner-iscsi'         
    
        - include: /chaoslib/openebs/inject_packet_loss_tc.yml
          vars:
            status: "induce"
            target_pod: "{{ cstor_target_pod.stdout }}"
            operator_namespace: "{{ operator_ns }}"
            containername: "cstor-istgt"                  
          when: 
            - stg_engine == 'cstor'

        - name: Wait for 240s post fault injection 
          wait_for:
            timeout: 240

        - include: /chaoslib/openebs/inject_packet_loss_tc.yml
          vars:
            status: "remove"
            target_pod: "{{ cstor_target_pod.stdout }}"
            operator_namespace: "{{ operator_ns }}"
            containername: "cstor-istgt"
          when:
            - stg_engine == 'cstor'

        - block:     
            - include: /chaoslib/openebs/inject_packet_loss_tc.yml
              vars:
                status: "remove"
                target_pod: "{{ controller_pod.stdout }}"
                operator_namespace: "{{ operator_ns }}"
                containername: "{{ pv.stdout }}-ctrl-con"
          when:
            - stg_prov == 'openebs.io/provisioner-iscsi'
            - stg_engine == 'jiva'

        ## POST-CHAOS APPLICATION LIVENESS CHECK

        - block:
            - name: Kill the application pod
              shell: >
                kubectl delete pod {{ app_pod_name.stdout }} -n {{ namespace }}
              args:
                executable: /bin/bash

            - name: Verify if the application pod is deleted
              shell: >
                kubectl get pods -n {{ namespace }}
              args:
                executable: /bin/bash
              register: podstatus
              until: '"{{ app_pod_name.stdout }}" not in podstatus.stdout'
              retries: 2
              delay: 150

            - name: Obtain the newly created pod name for application
              shell: >
                kubectl get pods -n {{ namespace }} -l {{ label }} -o jsonpath='{.items[].metadata.name}'
              args:
                executable: /bin/bash
              register: newpod_name

            - name: Checking application pod not in running state
              shell: >
                kubectl get pods -n {{ namespace }} 
                -o jsonpath='{.items[?(@.metadata.name=="{{ newpod_name.stdout }}")].status.containerStatuses[*].state}'
              register: result
              until: "'running' not in result.stdout"
              delay: 2
              retries: 150

          when: stg_prov == 'openebs.io/provisioner-iscsi'
       
        - set_fact:
            flag: "Pass"

      rescue:
        - set_fact:
            flag: "Fail"

      always:

        ## RECORD END-OF-TEST IN LITMUS RESULT CR

        - include_tasks: /utils/fcm/update_e2e_result_resource.yml
          vars:
            status: 'EOT'
            chaostype: target-network-loss
