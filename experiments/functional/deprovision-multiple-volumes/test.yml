---
- hosts: localhost
  connection: local
  gather_facts: False

  vars_files:
    - test_vars.yml

  tasks:
    - block:

          ## Generating the testname for deployment
        - include_tasks: /utils/fcm/create_testname.yml

        ## RECORD START-OF-TEST IN LITMUS RESULT CR
        - include_tasks: "/utils/fcm/update_e2e_result_resource.yml"
          vars:
            status: 'SOT'            
         
        ## VERIFY AVAILABILITY OF SELECTED STORAGE CLASS
        - name: Check whether the provider storageclass is provided.
          shell: kubectl get sc {{ lookup('env','PROVIDER_STORAGE_CLASS') }}
          args:
            executable: /bin/bash
          register: result

        - name: Create namespace for deployment.
          shell: kubectl create ns {{ namespace }}
          args:
            executable: /bin/bash
          register: app_ns
          failed_when: "'created' not in app_ns.stdout"

        - name: Replace the storageclass placeholder with provider
          replace:
            path: "{{ pvc_deployment }}"
            regexp: "testclass"
            replace: "{{ lookup('env','PROVIDER_STORAGE_CLASS') }}"

        ## Setting up iteration value to generate continuous values ##
        - set_fact:
            i: 0

        ## Required application and PVC creation tasks ##
        - include_tasks: "{{ pvc_creation_tasks }}"
          with_sequence: start=0 count={{ pvc_count }}

        - name: Obtain the cstor pool pod list
          shell: >
            kubectl get pods -n {{ operator_ns }} -l openebs.io/storage-pool-claim={{ pool_pod_label }}
            -o custom-columns=:.metadata.name --no-headers
          args:
            executable: /bin/bash
          register: pool_pods

        - name: Obtain the PV name
          shell: >
             kubectl get pvc -n {{ namespace }} -o custom-columns=:.spec.volumeName --no-headers
          args:
            executable: /bin/bash
          register: pv_name

        - name: Delete the all PVC and pool pods
          shell: >
             kubectl delete pods -n openebs {{ pool_pods.stdout_lines[0] }} && kubectl delete pvc -n {{ namespace }} --all
          args:
            executable: /bin/bash
          register: pod_pvc_delete

        - name: Check if the PVCs are deleted
          shell: kubectl get pvc -n {{ namespace }}
          args:
            executable: /bin/bash
          register: pvc_status
          until: "'No resources found.' in pvc_status.stderr"
          delay: 5
          retries: 30

        - name: Check if the pool pods are in Running state
          shell: >
             kubectl get pods -n {{ operator_ns }} -l openebs.io/storage-pool-claim={{ pool_pod_label }} 
             -o custom-columns=:.status.phase --no-headers
          args:
            executable: /bin/bash
          register: pool_pod_status
          until: "((pool_pod_status.stdout_lines|unique)|length) == 1 and 'Running' in pool_pod_status.stdout"
          delay: 5
          retries: 6   
        
        - name: Get the newly created pool pod list
          shell: >
             kubectl get pods -n {{ operator_ns }} -l openebs.io/storage-pool-claim={{ pool_pod_label }}
             -o custom-columns=:.metadata.name --no-headers
          args: 
            executable: /bin/bash
          register: new_pool_pod

        - name: Check if the CVRs are deleted
          shell: >
             kubectl get cvr -n {{ operator_ns }} -l openebs.io/persistent-volume={{ item }}
          args:
            executable: /bin/bash
          register: cvr_status
          until: "'No resources found.' in cvr_status.stderr"
          delay: 5
          retries: 12
          with_items:
            - "{{ pv_name.stdout_lines }}"

        - name: sleep for 30 seconds and continue with play
          wait_for: timeout=30

        - name: Check is the volumes are not present in cstor pool pods
          shell: >
             kubectl exec -it {{ item[0] }} -n {{ operator_ns }} -c cstor-pool -- zfs list | grep {{ item[1] }}
          args:
            executable: /bin/bash
          register: zfs_list
          failed_when: zfs_list.stdout != ""
          with_items:
            - "{{ new_pool_pod.stdout_lines }}"
            - "{{ pv_name.stdout_lines }}"

        - set_fact:
           flag: "Pass"

      rescue:
         - set_fact:
             flag: "Fail"

      always:
           ## RECORD END-OF-TEST IN LITMUS RESULT CR
        - include_tasks: /utils/fcm/update_e2e_result_resource.yml
          vars:
            status: 'EOT'            
